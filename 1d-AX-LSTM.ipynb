{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.polynomial import Polynomial\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from utilities import get_npz_data, get_bci_iii_data, get_project_data\n",
    "\n",
    "tf.random.set_seed(333)\n",
    "logger = logging.getLogger('1d-AX-LSTM')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard\n",
    "------\n",
    "#### Used to track the gridsearch and visualize the process of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f9a44fe551d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensorboard'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--logdir LOG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2342\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2344\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorboard/notebook.py\u001b[0m in \u001b[0;36m_start_magic\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_start_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;34m\"\"\"Implementation of the `%tensorboard` line magic.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorboard/notebook.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(args_string)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mparsed_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshlex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mstart_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStartLaunched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorboard/manager.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(arguments, timeout)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0mend_time_seconds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_time_seconds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mend_time_seconds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_interval_seconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0msubprocess_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubprocess_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir LOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49 files found.\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-1Cq5YjzM3eu-XaCck7Z5jQ_EPOCPLUS_37553_2022.02.24T14.45.30+01.00.csv\n",
      "Duration 25.64453125s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-5Ve2WqgPNmhLrb3_6rBndA_EPOCPLUS_37553_2022.02.24T14.58.44+01.00.csv\n",
      "Duration 25.390625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-b-e3bztqNa3Ce_biLVPMMw_EPOCPLUS_37553_2022.02.24T15.06.54+01.00.csv\n",
      "Duration 25.9140625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-bb8b0OAsspxDk2jwFWPFOQ_EPOCPLUS_37553_2022.02.24T14.19.40+01.00.csv\n",
      "Duration 25.609375s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-gXqLz0RyIYznyJCHuEiFxg_EPOCPLUS_37553_2022.02.24T14.05.13+01.00.csv\n",
      "Duration 26.05078125s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-tHSv5BsrzPVomLbFf23Lww_EPOCPLUS_37553_2022.02.24T15.08.56+01.00.csv\n",
      "Duration 26.16015625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-CelRByiPrzFM9BmpppdjsQ_EPOCPLUS_37553_2022.02.24T14.37.56+01.00.csv\n",
      "Duration 25.5859375s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-Ix7Z7w-P45fb1uF7Tz3xdA_EPOCPLUS_37553_2022.02.24T14.46.08+01.00.csv\n",
      "Duration 25.77734375s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-1BNALAxXgtYDjGrRjMb3qw_EPOCPLUS_37553_2022.02.24T14.10.32+01.00.csv\n",
      "Duration 25.46875s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-duri4KjEdsAj5ynVqMHAgA_EPOCPLUS_37553_2022.02.24T15.12.46+01.00.csv\n",
      "Duration 26.53125s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-QZItFtirGAM6oShN_xcljw_EPOCPLUS_37553_2022.02.24T14.09.57+01.00.csv\n",
      "Duration 25.48828125s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-Hcg5-5BRuDqzfrZVYju5Lg_EPOCPLUS_37553_2022.02.24T14.38.32+01.00.csv\n",
      "Duration 25.59765625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-BpRHddDXeYbrmifDXCCU5A_EPOCPLUS_37553_2022.02.24T15.10.50+01.00.csv\n",
      "Duration 26.29296875s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-_DpBFH0gHntlqPxvAMvCfg_EPOCPLUS_37553_2022.02.24T14.11.33+01.00.csv\n",
      "Duration 25.73046875s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-8aP8bZvolp2LeHkoevLlsg_EPOCPLUS_37553_2022.02.24T14.44.51+01.00.csv\n",
      "Duration 25.671875s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-IQt48zbmu_J2IhU9pyuf5g_EPOCPLUS_37553_2022.02.24T15.13.19+01.00.csv\n",
      "Duration 26.66015625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-4lTo8drLe03n6BFjHnjCzQ_EPOCPLUS_37553_2022.02.24T15.12.05+01.00.csv\n",
      "Duration 26.640625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-C6IrOWNiGQrb9kli0bfsWw_EPOCPLUS_37553_2022.02.24T14.39.42+01.00.csv\n",
      "Duration 25.87890625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-APTSQOr3H75vFqcebPoAKw_EPOCPLUS_37553_2022.02.24T14.44.16+01.00.csv\n",
      "Duration 25.58203125s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-YNmioZH4g0S48qzDJHw0Xg_EPOCPLUS_37553_2022.02.24T14.39.08+01.00.csv\n",
      "Duration 25.59375s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-da8kPNx67QKXuzNnkj-K-w_EPOCPLUS_37553_2022.02.24T14.21.05+01.00.csv\n",
      "Duration 25.89453125s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-rFJer-hCzqfIquZWxLDwvQ_EPOCPLUS_37553_2022.02.24T15.07.41+01.00.csv\n",
      "Duration 25.94921875s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-IZDrSdHrazdCpFrIMURw9g_EPOCPLUS_37553_2022.02.24T15.13.57+01.00.csv\n",
      "Duration 26.6640625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-lgCOnawlkYDWzJ8Laa60Jg_EPOCPLUS_37553_2022.02.24T15.03.46+01.00.csv\n",
      "Duration 25.53125s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-LUrscB_y-hk6hoFTD2kNIg_EPOCPLUS_37553_2022.02.24T15.11.27+01.00.csv\n",
      "Duration 26.34375s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-LMs2MEjHnYJwUleF1XbSQA_EPOCPLUS_37553_2022.02.24T14.48.00+01.00.csv\n",
      "Duration 25.828125s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex--KKPAsXZYmhTyLSbF65TJQ_EPOCPLUS_37553_2022.02.24T15.10.19+01.00.csv\n",
      "Duration 26.0625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-rOvZImMv2ATfY2SP5d8EKQ_EPOCPLUS_37553_2022.02.24T14.48.42+01.00.csv\n",
      "Duration 25.71875s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-FAjcXhEkWLgKujchQ-9acA_EPOCPLUS_37553_2022.02.24T14.36.29+01.00.csv\n",
      "Duration 25.5859375s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-lydZDdy7ilWCaCFfqroIVA_EPOCPLUS_37553_2022.02.24T15.05.41+01.00.csv\n",
      "Duration 25.890625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-IfvQ1vzv0XYBNeS6NI-3Zg_EPOCPLUS_37553_2022.02.24T14.12.16+01.00.csv\n",
      "Duration 25.65625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-WhieaXozPZOqnfGDjTmeHg_EPOCPLUS_37553_2022.02.24T15.06.21+01.00.csv\n",
      "Duration 25.76171875s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-d8G6i2Rgc5V9aMOib35xEA_EPOCPLUS_37553_2022.02.24T14.06.45+01.00.csv\n",
      "Duration 26.16015625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-qOmikGczk0qlNW6e8cu-GA_EPOCPLUS_37553_2022.02.24T14.02.21+01.00.csv\n",
      "Duration 26.12890625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-G4MJvXWzYYz-GtN40BXXGg_EPOCPLUS_37553_2022.02.24T15.04.59+01.00.csv\n",
      "Duration 25.7890625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-NxSOzVBxLNPWugHw-odkuw_EPOCPLUS_37553_2022.02.24T14.09.22+01.00.csv\n",
      "Duration 25.3515625s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-Go3bIawURHsVmmreT6gbLQ_EPOCPLUS_37553_2022.02.24T14.31.30+01.00.csv\n",
      "Duration 25.484375s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-UauMEZfyB5z8zaM_lXWmLQ_EPOCPLUS_37553_2022.02.24T15.01.50+01.00.csv\n",
      "Duration 25.421875s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-83D1fJOnVrdCYG9cAWMtsA_EPOCPLUS_37553_2022.02.24T15.08.18+01.00.csv\n",
      "Duration 26.07421875s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-Yph9AJJ3E4GY-lBHMkzR9w_EPOCPLUS_37553_2022.02.24T14.08.09+01.00.csv\n",
      "Duration 25.7109375s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-mf9GIXDR-izZm3jHnx4q1w_EPOCPLUS_37553_2022.02.24T15.14.30+01.00.csv\n",
      "Duration 26.75s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-g1tk7joMKNYY1ygi-bslig_EPOCPLUS_37553_2022.02.24T14.03.35+01.00.csv\n",
      "Duration 26.0546875s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-5Ukeqks_0JM6-VCJF6rcVA_EPOCPLUS_37553_2022.02.24T14.32.30+01.00.csv\n",
      "Duration 25.3125s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-vrVBBihk_cllDkTgJq5Pbw_EPOCPLUS_37553_2022.02.24T14.47.17+01.00.csv\n",
      "Duration 25.69921875s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-S7pIv4NeCjrzs9za5TaB-w_EPOCPLUS_37553_2022.02.24T15.04.25+01.00.csv\n",
      "Duration 25.82421875s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-iF3CKnFDH9BhFS_tC_dmFQ_EPOCPLUS_37553_2022.02.24T14.08.45+01.00.csv\n",
      "Duration 25.421875s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-2W2ubHBQEHrdGoGStvV8-A_EPOCPLUS_37553_2022.02.24T14.20.30+01.00.csv\n",
      "Duration 25.7578125s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-eBJ1yEdXp2iUAQUfoZpiGQ_EPOCPLUS_37553_2022.02.24T14.13.04+01.00.csv\n",
      "Duration 25.9453125s\n",
      "\n",
      "Fetching from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/Hybrid/Alex-UBVsMKyfdI5HvV9ToOR8UA_EPOCPLUS_37553_2022.02.24T15.00.20+01.00.csv\n",
      "Duration 25.41015625s\n",
      "\n",
      "*** Import done ***\n",
      "RAW EEG Data of shapes: (98, 768, 14)\n",
      "TARGET of shape: (98,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOG_PATH = f'{os.getcwd()}/LOG/1dAX_LSTM'\n",
    "\n",
    "HYBRID_DATA_PATH = f'{os.getcwd()}/Data/Hybrid'\n",
    "BCI_IV_2a_DATA_PATH = f'{os.getcwd()}/Data/BCI'\n",
    "BCI_III_IVa_DATA_PATH = f'{os.getcwd()}/Data/BCI III IVa'\n",
    "\n",
    "EEG, TARGET = get_project_data(HYBRID_DATA_PATH, [2.0, 3.0], sec=3, offset=1)\n",
    "\n",
    "if not os.path.exists(LOG_PATH):\n",
    "    os.makedirs(LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "----\n",
    "#### The first preprocessing step is the normalisation. The scheme for this is the follwing. Let us consider $\\mathbf{X}_{\\mathrm{EEG}}=[\\mathbf{x}^{(1)},\\ldots, \\mathbf{x}^{(N)}]\\in \\mathbb{R}^{k \\times N}$, where $k$ are the amount of channels and $N$ the observations. Then we take a vector $\\mathbf{x}_{k}=[\\mathrm{x}^{(1)}_{k},\\ldots, \\mathrm{x}^{(N)}_{k}]$, calculate its mean $\\mu_{k}$, standard deviation $\\sigma_{k}$ and normalise it as $\\mathbf{\\bar{x}}_{k}=[\\frac{\\mathrm{x}^{(1)}_{k}-\\mu_{k}}{\\sigma_{k}},\\ldots, \\frac{\\mathrm{x}^{(N)}_{k}-\\mu_{k}}{\\sigma_{k}}]$. Repeating this for each channel, we get $\\mathbf{\\bar{X}}_{\\mathrm{EEG}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _preprocessing(data):\n",
    "    logger.info(f'Preprocessing data')\n",
    "    normalized_data = np.empty(shape=data.shape)\n",
    "    for idx, trial in enumerate(data):\n",
    "        normalized_data[idx] = StandardScaler().fit_transform(X=trial)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "### One Dimension-Aggregate Approximation (1d-AX)\n",
    "----\n",
    "1d-AX  can calculated by taking $\\mathrm{\\bar{x}}_{k}=[\\mathrm{\\bar{x}}^{(1)}_{k},\\ldots, \\mathrm{\\bar{x}}^{(N)}_{k}]$ for each channel, and divide it into $m$ segements $\\mathbf{y}_{k}^{(i)}$ of equal length $q=\\frac{N}{m}$. Afterwards, we take a sampled version of $\\mathbf{y}_{k}^{(i)}$ and apply linear regression to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _segment_data(data, seg_length):\n",
    "    logger.info(f'Segmenting data')\n",
    "    num_trials, num_samples, num_channels = data.shape\n",
    "    assert num_samples % seg_length == 0\n",
    "    num_segments = num_samples//seg_length\n",
    "    seg_eeg_data = np.empty(shape=(num_trials, num_segments, seg_length, num_channels))\n",
    "\n",
    "    for trial_idx in range(num_trials):\n",
    "        for segment_idx in range(num_segments):\n",
    "            lower_limit = segment_idx * seg_length\n",
    "            upper_limit = lower_limit + seg_length\n",
    "            seg_eeg_data[trial_idx, segment_idx] = data[trial_idx, lower_limit:upper_limit, :]\n",
    "\n",
    "    return seg_eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _linear_regression(data):\n",
    "    num_trials, num_segments, num_samples, num_channels = data.shape\n",
    "    x = np.linspace(1, num_samples, num_samples)\n",
    "\n",
    "    K = np.zeros(shape=(num_trials, num_segments, num_channels))\n",
    "    A = np.zeros(shape=(num_trials, num_segments, num_channels))\n",
    "    for trial_idx, trial in enumerate(data):\n",
    "        for segment_idx, segment in enumerate(trial):\n",
    "            for channel_idx in range(num_channels):\n",
    "                (c1, c0) = np.polyfit(x, segment[:, channel_idx], deg=1)\n",
    "                t_mean = np.mean(segment[:, channel_idx])\n",
    "                K[trial_idx, segment_idx, channel_idx] = c1\n",
    "                A[trial_idx, segment_idx, channel_idx] = c1 * t_mean + c0\n",
    "\n",
    "    return K, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel Weighting\n",
    "----\n",
    "#### Following the 1d-AX step, we calculate spatial filters for dimensionality reduction. The idea is to gain filters $\\mathbf{W_{\\mathbf{K}}}$ and $\\mathbf{W_{\\mathbf{A}}}$, which reduce the dimensionality of $\\mathbf{K}$ and $\\mathbf{A}$ by taking $\\mathbf{K}'=\\mathbf{W_{\\mathbf{K}}}\\mathbf{K}$, as well as $\\mathbf{A}'=\\mathbf{W_{\\mathbf{A}}}\\mathbf{A}$.\n",
    "\n",
    "# LSTM and Softmax Regression\n",
    "----\n",
    "#### Subsequently, the output of the filters $\\mathbf{K}'$, $\\mathbf{A}'$ is fed into two LSTMs in parallel. Output of the LSTM is merged and fed into a Softmax Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _fit(data, num_reduced_channels, LSTM_cells, num_classes):\n",
    "    num_samples, num_segments, num_channels = data.shape\n",
    "    \n",
    "    if num_classes == 4:\n",
    "        Input = tf.keras.Input(shape=(num_segments, num_channels), batch_size=None)\n",
    "        Input_f = tf.keras.layers.Dense(num_reduced_channels)(Input)\n",
    "        Input_f_norm = tf.keras.layers.BatchNormalization()(Input_f)\n",
    "        LSTM = tf.keras.layers.LSTM(LSTM_cells, dropout=0.6)(Input_f_norm)\n",
    "        Output = tf.keras.layers.Dense(num_classes, activation='softmax')(LSTM)\n",
    "\n",
    "        return tf.keras.Model(inputs=Input, outputs=Output)\n",
    "    \n",
    "    else:\n",
    "        Input_K = tf.keras.Input(shape=(num_segments, num_channels), batch_size=None)\n",
    "        Input_A = tf.keras.Input(shape=(num_segments, num_channels), batch_size=None)\n",
    "        Input_K_f = tf.keras.layers.Dense(num_reduced_channels)(Input_K)\n",
    "        Input_A_f = tf.keras.layers.Dense(num_reduced_channels)(Input_A)\n",
    "        Input_K_f_norm = tf.keras.layers.BatchNormalization()(Input_K_f)\n",
    "        Input_A_f_norm = tf.keras.layers.BatchNormalization()(Input_A_f)\n",
    "        LSTM_K = tf.keras.layers.LSTM(LSTM_cells, dropout=0.6)(Input_K_f_norm)\n",
    "        LSTM_A = tf.keras.layers.LSTM(LSTM_cells, dropout=0.6)(Input_A_f_norm)\n",
    "        Merged_LSTM = tf.keras.layers.concatenate([LSTM_K, LSTM_A])\n",
    "        Output = tf.keras.layers.Dense(num_classes, activation='softmax')(Merged_LSTM)\n",
    "\n",
    "        return tf.keras.Model(inputs=[Input_K, Input_A], outputs=Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a model on a given set of training features and labels\n",
    "_______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _train(K, A, target, spatial_filter_dim, LSTM_cells, num_classes, epochs, learning_rate, verbose, batch_size, log_dir):\n",
    "    \n",
    "    model = _fit(data=K, num_reduced_channels=spatial_filter_dim, LSTM_cells=LSTM_cells, num_classes=num_classes)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics = [tf.keras.metrics.CategoricalAccuracy()]\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)\n",
    "    callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    if num_classes == 4:\n",
    "        model.fit([A], target, epochs=epochs, verbose=verbose, batch_size=batch_size, callbacks=[callback])\n",
    "    \n",
    "    else:\n",
    "        model.fit([K, A], target, epochs=epochs, verbose=verbose, batch_size=batch_size, callbacks=[callback])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating a model on a given set of test data and labels\n",
    "_______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(data, target, model, segment_length, num_classes, batch_size, log_dir):\n",
    "    new_target = map_to_one_hot(target)\n",
    "    normalized_data = _preprocessing(data)\n",
    "    segmented_data = _segment_data(normalized_data, segment_length)\n",
    "    K, A = _linear_regression(segmented_data)\n",
    "    callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    if num_classes == 4:\n",
    "        loss, acc = model.evaluate([A], new_target, callbacks=[callback])\n",
    "        pred_label = model.predict(A, batch_size=batch_size)\n",
    "        \n",
    "    else:\n",
    "        loss, acc = model.evaluate([K, A], new_target, callbacks=[callback])\n",
    "        pred_label = model.predict([K, A], batch_size=batch_size)\n",
    "    \n",
    "    return acc, tf.math.confusion_matrix(tf.math.argmax(new_target, axis=1),tf.math.argmax(pred_label, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for training the model on a given data and labels\n",
    "______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pipeline(data, target, segment_length, spatial_filter_dim, LSTM_cells, num_classes, epochs, batch_size, log_dir, verbose=0, learning_rate=3e-4):\n",
    "    new_target = map_to_one_hot(target)\n",
    "    normalized_data = _preprocessing(data)\n",
    "    segmented_data = _segment_data(normalized_data, segment_length)\n",
    "    K, A = _linear_regression(segmented_data)\n",
    "    model = _train(K, A, target=new_target, \n",
    "                   spatial_filter_dim=spatial_filter_dim, LSTM_cells=LSTM_cells, \n",
    "                   num_classes=num_classes, epochs=epochs, \n",
    "                   learning_rate=learning_rate, verbose=verbose, \n",
    "                   batch_size=batch_size, log_dir=log_dir)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Mapping class labels to a categorical variable.\n",
    " ______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def map_to_one_hot(target):\n",
    "    new_target = np.copy(target)\n",
    "    unique = np.unique(target)\n",
    "    new_labels = np.linspace(0, len(unique)-1, len(unique))\n",
    "    mapping = dict(zip(unique, new_labels))\n",
    "    for idx, label in enumerate(target):\n",
    "        new_target[idx] = mapping[label]\n",
    "    return tf.one_hot(new_target, depth=len(unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of a possible training scheme\n",
    "-------\n",
    "Define parameters if interest, i.e. LSTM cells or dimension of the spatial filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching npz data from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/BCI/A01E.npz\n",
      "\n",
      "Import of BCI Competition IV 2a dataset done\n",
      "Shape of data (144, 750, 22) and targets (144,)\n",
      "\n",
      "Preprocessing data\n",
      "Segmenting data\n",
      "Preprocessing data\n",
      "Segmenting data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 498ms/step - loss: 0.6493 - categorical_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data\n",
      "Segmenting data\n",
      "Preprocessing data\n",
      "Segmenting data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 464ms/step - loss: 0.6969 - categorical_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data\n",
      "Segmenting data\n",
      "Preprocessing data\n",
      "Segmenting data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 459ms/step - loss: 0.7136 - categorical_accuracy: 0.4483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data\n",
      "Segmenting data\n",
      "Preprocessing data\n",
      "Segmenting data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 473ms/step - loss: 0.6984 - categorical_accuracy: 0.4483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data\n",
      "Segmenting data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-452857926dd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                          log_dir=log_dir)\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         acc, _ = evaluate(data=EEG_TEST, target=TARGET_TEST,\n",
      "\u001b[0;32m<ipython-input-10-a33b4e1bddd4>\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(data, target, segment_length, spatial_filter_dim, LSTM_cells, num_classes, epochs, batch_size, log_dir, verbose, learning_rate)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnormalized_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msegmented_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_segment_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_linear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmented_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     model = _train(K, A, target=new_target, \n\u001b[1;32m      7\u001b[0m                    \u001b[0mspatial_filter_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspatial_filter_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM_cells\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLSTM_cells\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-7e9a85678b48>\u001b[0m in \u001b[0;36m_linear_regression\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msegment_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mchannel_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mt_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpolyfit\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/lib/polynomial.py\u001b[0m in \u001b[0;36mpolyfit\u001b[0;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0mlhs\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m     \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m  \u001b[0;31m# broadcast scale coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, rcond)\u001b[0m\n\u001b[1;32m   2304\u001b[0m         \u001b[0;31m# lapack can't handle n_rhs = 0 - so allocate the array one larger in that axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2305\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rhs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2306\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2307\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2308\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k_cross_val = 5\n",
    "num_segments = 6\n",
    "t_sec = 3\n",
    "epochs=300\n",
    "spatial_filter_dim, LSTM_cells =  6, 8\n",
    "learning_rate = 3e-4\n",
    "batch_size=64\n",
    "\n",
    "for comb_idx, comb in enumerate([[769, 770], [770, 772]]):\n",
    "    EEG, TARGET, _ = get_npz_data(path=BCI_IV_2a_DATA_PATH, user='A01E', labels=comb, sec=t_sec)\n",
    "    for split_idx, (train_idx, test_idx) in enumerate(StratifiedKFold(n_splits=k_cross_val).split(np.zeros(shape=TARGET.shape), TARGET)):\n",
    "        EEG_TRAIN, TARGET_TRAIN = EEG[train_idx], TARGET[train_idx]\n",
    "        EEG_TEST, TARGET_TEST = EEG[test_idx], TARGET[test_idx]\n",
    "        \n",
    "        num_classes = len(set(TARGET_TRAIN))\n",
    "        _, samples_per_trial, _ = EEG_TRAIN.shape\n",
    "        log_dir = f'{LOG_PATH}/CIDX-{comb_idx}-SIDX-{split_idx}-{comb[0]}-{comb[1]}/'\n",
    "\n",
    "        model = pipeline(data=EEG_TRAIN, target=TARGET_TRAIN, \n",
    "                         segment_length=samples_per_trial//num_segments, \n",
    "                         spatial_filter_dim=spatial_filter_dim, \n",
    "                         LSTM_cells=LSTM_cells, \n",
    "                         num_classes=num_classes,\n",
    "                         learning_rate=learning_rate,\n",
    "                         batch_size=batch_size,\n",
    "                         epochs=epochs,\n",
    "                         log_dir=log_dir)\n",
    "        \n",
    "        acc, _ = evaluate(data=EEG_TEST, target=TARGET_TEST,\n",
    "                          model=model, \n",
    "                          segment_length=samples_per_trial//num_segments,\n",
    "                          num_classes=num_classes,\n",
    "                          batch_size=batch_size,\n",
    "                          log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Search\n",
    "----------\n",
    "#### Adapt the parameters _learning_rates_, _filter_dim_, _lstm_cells_, _num_segments_ and _epochs_ before starting the hypterparamter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "GRIDSEARCH_PATH = 'LOG/Gridsearch'\n",
    "\n",
    "learning_rates = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "filter_dim = [3, 6, 9, 12]\n",
    "lstm_cells = [3, 5, 8, 10]\n",
    "num_segments = [3, 5, 6, 10]\n",
    "epochs = [250, 500, 1000]\n",
    "\n",
    "HP_LEARNING_RATE = hp.HParam('Learning Rate', hp.Discrete(learning_rates))\n",
    "HP_FILTER_DIM = hp.HParam('Filter Dimension', hp.Discrete(filter_dim))\n",
    "HP_LSTM_CELLS = hp.HParam('LSTM Cells', hp.Discrete(lstm_cells))\n",
    "HP_NUM_SEGMENTS = hp.HParam('Number of Segments', hp.Discrete(num_segments))\n",
    "HP_EPOCHS = hp.HParam('Epochs', hp.Discrete(epochs))\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "\n",
    "def run(path, hparams, train_data, train_labels, test_data, test_labels, batch_size, samples_per_trial, fold_idx):\n",
    "        hp.hparams(hparams)\n",
    "        model = pipeline(data=train_data, target=train_labels,\n",
    "                         segment_length=samples_per_trial//hparams[HP_NUM_SEGMENTS], \n",
    "                         spatial_filter_dim=hparams[HP_FILTER_DIM], \n",
    "                         LSTM_cells=hparams[HP_LSTM_CELLS], \n",
    "                         num_classes=len(set(train_labels)),\n",
    "                         learning_rate=hparams[HP_LEARNING_RATE],\n",
    "                         batch_size=batch_size,\n",
    "                         epochs=hparams[HP_EPOCHS], \n",
    "                         log_dir=path)\n",
    "        \n",
    "        accuracy, _ = evaluate(data=test_data, target=test_labels,\n",
    "                               model=model,\n",
    "                               segment_length=samples_per_trial//hparams[HP_NUM_SEGMENTS],\n",
    "                               num_classes=len(set(train_labels)),\n",
    "                               batch_size=batch_size,\n",
    "                               log_dir=path)\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching npz data from /upb/scratch/users/d/dann/1d-AX-LSTM/Data/BCI/A01E.npz\n",
      "\n",
      "Import of BCI Competition IV 2a dataset done\n",
      "Shape of data (288, 750, 22) and targets (288,)\n",
      "\n",
      "Preprocessing data\n",
      "Preprocessing data\n",
      "Segmenting data\n",
      "Segmenting data\n",
      "Preprocessing data\n",
      "Preprocessing data\n",
      "Segmenting data\n",
      "Segmenting data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3835 - categorical_accuracy: 0.2241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data\n",
      "Preprocessing data\n",
      "Segmenting data\n",
      "Segmenting data\n"
     ]
    }
   ],
   "source": [
    "EEG, TARGET, _ = get_npz_data(BCI_IV_2a_DATA_PATH, 'A01E')\n",
    "_, samples_per_trial, _ = EEG.shape\n",
    "session_idx = 0\n",
    "batch_size = 64\n",
    "\n",
    "for lr_idx, lr in enumerate(HP_LEARNING_RATE.domain.values, 0):\n",
    "    for fdim_idx, fdim in enumerate(HP_FILTER_DIM.domain.values, 0):\n",
    "        for cells_idx, cells in enumerate(HP_LSTM_CELLS.domain.values, 0):\n",
    "            for segment_idx, N in enumerate(HP_NUM_SEGMENTS.domain.values, 0):\n",
    "                for epoch_idx, epoch_N in enumerate(HP_EPOCHS.domain.values, 0):\n",
    "                    hparams = {\n",
    "                        HP_LEARNING_RATE: lr,\n",
    "                        HP_FILTER_DIM: fdim,\n",
    "                        HP_LSTM_CELLS: cells,\n",
    "                        HP_NUM_SEGMENTS: N,\n",
    "                        HP_EPOCHS: epoch_N\n",
    "                    }\n",
    "                    \n",
    "                    accuracies = list()\n",
    "                    path = f'{GRIDSEARCH_PATH}/grid-{session_idx}/'\n",
    "                    with tf.summary.create_file_writer(path).as_default(): \n",
    "                        for fold_idx, (train_idx, test_idx) in enumerate(StratifiedKFold(n_splits=5).split(np.zeros(shape=TARGET.shape), TARGET)):\n",
    "                            EEG_TRAIN, TARGET_TRAIN = EEG[train_idx], TARGET[train_idx]\n",
    "                            EEG_TEST, TARGET_TEST = EEG[test_idx], TARGET[test_idx]\n",
    "\n",
    "                            acc = run(path=f'{path}/fold-{fold_idx}', hparams=hparams, \n",
    "                                      train_data=EEG_TRAIN, train_labels=TARGET_TRAIN, \n",
    "                                      test_data=EEG_TEST, test_labels=TARGET_TEST, \n",
    "                                      batch_size=batch_size, samples_per_trial=samples_per_trial,\n",
    "                                      fold_idx=fold_idx)\n",
    "                            accuracies.append(acc)\n",
    "\n",
    "                        tf.summary.scalar(METRIC_ACCURACY, tf.reduce_mean(accuracies), step=session_idx)\n",
    "                        session_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
